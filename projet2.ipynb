{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Projet Maison 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import des modules usuels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "# options d'affichage\n",
    "pd.set_option(\"display.min_rows\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chargement et traitement des données\n",
    "GEO = pd.read_csv(\"correspondance-code-insee-code-postal.csv\",\n",
    "                   sep=';',\n",
    "                   usecols=range(11),\n",
    "                   index_col=\"Code INSEE\")\n",
    "\n",
    "# A COMPLETER avec les colonnes\n",
    "# - lat, lon : latitude et longitude des communes\n",
    "GEO['lat'] = GEO['geo_point_2d'].str.split(',').str.get(0)\n",
    "GEO['lon'] = GEO['geo_point_2d'].str.split(',').str.get(1)\n",
    "\n",
    "GEO = GEO.astype({'lat':float, 'lon':float})\n",
    "\n",
    "# - cp_ville : Code Postal + \" \" + \"Commune\"\n",
    "GEO['cp_ville'] = GEO['Code Postal'] + \" \" + GEO['Commune']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partie A**\n",
    "\n",
    "- Compléter le chargement des données en ajoutant au dataframe `GEO`\n",
    "    - les colonnes \"lat\" et \"lon\" avec la latitude et la longitude des communes\n",
    "    - une colonne \"cp_ville\" avec le Code Postal + un espace + et le nom de la Commune\n",
    "- Ecrire une fonction `search_city(lat, lon)` qui retourne le \"cp_ville\" de la commune la plus proche d'un point à partir de sa latitude et sa longitude.\n",
    "- Ecrire une fonction `dms2dec(deg, min, sec)` qui convertit les degrés, minutes, secondes en valeur numérique pour pouvoir utiliser la fonction précédente avec un GPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fonction recherche de ville\n",
    "def search_city(lat, long):\n",
    "    sub_geo = pd.DataFrame(GEO[['cp_ville', 'lat', 'lon']])\n",
    "    sub_geo['distance'] = np.sqrt((lat - sub_geo['lat'])**2 + (long - sub_geo['lon'])**2)\n",
    "    return sub_geo.loc[sub_geo['distance'] == sub_geo['distance'].min()]['cp_ville'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# conversion degrés, minutes, secondes => décimal\n",
    "def dms2dec(deg, mn, sec):\n",
    "    return deg + (mn / 60) + (sec / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['71330 BOSJEAN'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on applique la fonction à une coordonnée tirée au hasard\n",
    "np.random.seed(0)\n",
    "a, b = 41.5, 51.1  # latitude min et max de la France métropolitaine\n",
    "lat = np.random.uniform(a, b)\n",
    "a, b = -5.1, 9.5  # longitude min et max de la France métropolitaine\n",
    "lon = np.random.uniform(a, b)\n",
    "\n",
    "search_city(lat, lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['91120 PALAISEAU'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# à partir de coordonnées GPS précises\n",
    "search_city(dms2dec(48, 42, 52), dms2dec(2, 14, 45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partie B**\n",
    "\n",
    "La colonne \"geo_shape\" comporte des chaines de catactères au format JSON. Elles représentent les formes géométriques des communes qui sont soit des polygones soit composées de plusieurs polygones.\n",
    "\n",
    "- Utiliser la librairie Python **json** pour parser les valeurs de la colonne \"geo_shape\" et mettre le résultat (`Series`) dans la variable `GEO_SHAPE`.\n",
    "- Ecrire une fonction `get_types()` qui retourne le décompte (`value_counts()`) des valeurs accédées avec la clé \"type\".\n",
    "- Ecrire une fonction `get_coordinates_len()` qui retourne le décompte (`value_counts()`) des longueurs des listes accédées avec la clé \"coordinates\".\n",
    "- Ecrire une fonction `get_most_complex_city()` qui retourne la commune est constituée du plus grand nombre de polygones ?\n",
    "- Ecrire une fonction `get_nb_cities_2_polygons()` qui retourne  le nombre de villes qui sont de type \"Polygon\" mais dont la longueur des listes accédées avec la clé \"coordinates\" vaut 2 ?\n",
    "- **Facultatif :**\n",
    "- Pour ces villes vérifier que le premier polygone contient bien le second (enclave). NB : on pourra installer la librairie **shapely**, utiliser la classe Polygon de **shapely.geometry**  et la méthode `contains()`. Sur Windows **shapely** peut nécessiter d'installer manuellement la dll \"geos_c.dll\" dans le répertoire \"Library/bin\" de votre environnement Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEO_SHAPE\n",
    "# La variable GEO_SHAPE doit contenir une Serie\n",
    "# correspondant aux valeurs de la colonne \"geo_shape\" parsées avec la librairie json\n",
    "data = [dict] * len(GEO)\n",
    "for i in range(len(GEO)):\n",
    "    data[i] = json.loads(GEO['geo_shape'][i])\n",
    "    \n",
    "GEO_SHAPE = pd.Series(data = data, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts des valeurs \"type\"\n",
    "def get_types():\n",
    "    # returns dictionary of types and value_counts() of types -- me\n",
    "    dict_types = {}\n",
    "    for i in range(len(GEO_SHAPE)):\n",
    "        type_i = GEO_SHAPE[i]['type']\n",
    "        \n",
    "        if type_i in dict_types:\n",
    "            dict_types[type_i] = dict_types[type_i] + 1\n",
    "        else:\n",
    "            dict_types[type_i] = 1\n",
    "    return dict_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts des longueurs de \"coordinates\"\n",
    "def get_coordinates_len():\n",
    "    # returns dictionary of list_length (a.k.a number of polygons) and value_counts() of each list length -- me\n",
    "    dict_coordinates = {}\n",
    "    \n",
    "    for i in range(len(GEO_SHAPE)):\n",
    "        coordinates_i = GEO_SHAPE[i]['coordinates']\n",
    "        len_coordinates_i = len(coordinates_i)\n",
    "        if len_coordinates_i in dict_coordinates:\n",
    "            dict_coordinates[len_coordinates_i] = dict_coordinates[len_coordinates_i] + 1\n",
    "        else:\n",
    "            dict_coordinates[len_coordinates_i] = 1\n",
    "            \n",
    "    return dict_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commune constituée du plus grand nombre de polygones\n",
    "def get_most_complex_city():\n",
    "    \n",
    "    polygon_size = [int] * len(GEO_SHAPE)\n",
    "    for i in range(len(GEO_SHAPE)):\n",
    "        polygon_size[i] = len(GEO_SHAPE[i]['coordinates'])\n",
    "        \n",
    "    GEO['polygon_size'] = polygon_size\n",
    "\n",
    "    return GEO.loc[GEO['polygon_size']==GEO['polygon_size'].max()]['cp_ville'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de communes constituées 2 polygones mais de type Polygon\n",
    "def get_nb_cities_2_polygons():\n",
    "    \n",
    "    geo_shape_type = [str] * len(GEO_SHAPE)\n",
    "    for i in range(len(GEO_SHAPE)):\n",
    "        geo_shape_type[i] = GEO_SHAPE[i]['type']\n",
    "        \n",
    "    GEO['geo_shape_type'] = geo_shape_type\n",
    "    \n",
    "    return len(GEO.loc[(GEO['geo_shape_type'] == 'Polygon') & (GEO['polygon_size']==2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "import unittest\n",
    "\n",
    "class Session2Test(unittest.TestCase):\n",
    "    \n",
    "    def test_partie_A1(self):\n",
    "        # on applique la fonction cherche_ville() à une coordonnée tirée au hasard\n",
    "        np.random.seed(0)\n",
    "        a, b = 41.5, 51.1  # latitude min et max de la France métropolitaine\n",
    "        lat = np.random.uniform(a, b)\n",
    "        a, b = -5.1, 9.5  # longitude min et max de la France métropolitaine\n",
    "        lon = np.random.uniform(a, b)\n",
    "\n",
    "        cp_ville = search_city(lat, lon)\n",
    "        self.assertEqual(cp_ville, \"71330 BOSJEAN\")\n",
    "        \n",
    "    def test_partie_A2(self):\n",
    "        # à partir de coordonnées GPS précises\n",
    "        cp_ville = search_city(dms2dec(48, 42, 52), dms2dec(2, 14, 45))\n",
    "        self.assertEqual(cp_ville, \"91120 PALAISEAU\")\n",
    "        \n",
    "    def test_partie_B1(self):\n",
    "        # check types\n",
    "        dico = get_types()\n",
    "        self.assertEqual(dico[\"Polygon\"], 36670)\n",
    "        self.assertEqual(dico[\"MultiPolygon\"], 72)\n",
    "        \n",
    "    def test_partie_B2(self):\n",
    "        # check coordinates len\n",
    "        dico = get_coordinates_len()\n",
    "        self.assertEqual(dico[1], 36660)\n",
    "        self.assertEqual(dico[2], 80)\n",
    "\n",
    "    def test_partie_B3(self):\n",
    "        # check most complex city\n",
    "        cp_ville = get_most_complex_city()\n",
    "        self.assertEqual(cp_ville, \"83400 HYERES\")\n",
    "        \n",
    "    def test_partie_B4(self):\n",
    "        # check nb cities 2 polygons\n",
    "        nb = get_nb_cities_2_polygons()\n",
    "        self.assertEqual(nb, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_partie_A1 (__main__.Session2Test) ... ok\n",
      "test_partie_A2 (__main__.Session2Test) ... ok\n",
      "test_partie_B1 (__main__.Session2Test) ... ok\n",
      "test_partie_B2 (__main__.Session2Test) ... ok\n",
      "test_partie_B3 (__main__.Session2Test) ... ok\n",
      "test_partie_B4 (__main__.Session2Test) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.528s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run tests\n",
    "def run_tests():\n",
    "    test_suite = unittest.makeSuite(Session2Test)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(test_suite)\n",
    "    \n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
